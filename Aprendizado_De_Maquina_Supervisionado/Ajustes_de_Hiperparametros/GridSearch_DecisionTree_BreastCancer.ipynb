{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkwlzK/wbGXnJ8XDZIi56p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romulo-souza/IA/blob/main/Aprendizado_De_Maquina_Supervisionado/Ajustes_de_Hiperparametros/GridSearch_DecisionTree_BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base de Dados: Breast Cancer\n",
        "* Base de dados: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data (baixar e colocar em arquivos no Drive)\n",
        "* Classe: Diagnosis (M = malignant, B = benign)\n",
        "* Usaremos o algoritmo de arvore de decisão (decision tree) do scikitlearn. LINK: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ],
      "metadata": {
        "id": "TBmmdxE2_uRu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bgrNjFnL_dV6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Modelo machine learning\n",
        "from sklearn.model_selection import train_test_split #amostragem por holdout\n",
        "from sklearn.preprocessing import StandardScaler #normalização, nesse caso será z score\n",
        "from sklearn.tree import DecisionTreeClassifier #Algortimo de classificação é a arvore de decisão\n",
        "from sklearn.preprocessing import LabelEncoder #transformar dados categoricos (classe diagnosis) em numéricos\n",
        "\n",
        "# Amostragem por Validação Cruzada\n",
        "from sklearn.model_selection import (\n",
        "    KFold, #modelo de validação cruzada\n",
        "    LeaveOneOut, #modelo de validação cruzada\n",
        "    StratifiedKFold, #modelo de validação cruzada\n",
        "    cross_validate #classe, função que realiza a validação cruzada\n",
        ")\n",
        "\n",
        "# Métricas\n",
        "from sklearn.metrics import (recall_score,\n",
        "                             accuracy_score,\n",
        "                             precision_score,\n",
        "                             f1_score)\n",
        "from sklearn.metrics import classification_report # Extrato geral das matricas de classificação"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para carregar/gerar Base de Dados (Dataframe)\n",
        "def carregaBaseDados(nome):\n",
        "  return pd.read_csv(nome)#retorna um dataframe\n"
      ],
      "metadata": {
        "id": "1xUNnOadk2eO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento\n",
        "* Parametros da função\n",
        "* dataframe - > dataframe que foi retornado na função carregaBaseDados\n",
        "* rem_cols - > Colunas a serem removidas, serão passadas em forma de uma lista\n",
        "* class_column -> Nome da coluna que é a classe alvo, nesse caso é a coluna diagnosis\n",
        "* normalization_cols -> Especificar quais colunas serão normalizadas,  serão passadas em forma de uma lista\n",
        "\n",
        "obs.: A normalização deve ser aplicada apenas às colunas que são originalmente numéricas na base de dados. As colunas categóricas, mesmo após serem transformadas em números inteiros pelo LabelEncoder, não devem ser normalizadas. Isso ocorre porque o LabelEncoder atribui números inteiros arbitrários às categorias, mas esses números não têm uma ordem ou escala significativa. Normalizar esses dados pode introduzir distorções que não fazem sentido para o modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "UKky_mYpl0nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preProcessamento(dataframe, rem_cols, class_column, normalization_cols):\n",
        "\n",
        "  #Remoção das colunas irrelevantes\n",
        "  dataframe.drop(rem_cols, axis = 1, inplace = True) #axis = 1 pois é uma coluna, inplace = True para substituir o dataframe original por esse\n",
        "\n",
        "  #Transformar dados categóricos da classe 'diagnosis' em dados numéricos\n",
        "  le = LabelEncoder()\n",
        "  dataframe[class_column] = le.fit_transform(dataframe[class_column]) #os valores categoricos da coluna que tem a classe 'diagnosis' serão substiuídos por uma coluna com valores discretizados (numericos)\n",
        "\n",
        "  #Normalização dos dados\n",
        "  scaler = StandardScaler()\n",
        "  dataframe[normalization_cols] = scaler.fit_transform(dataframe[normalization_cols]) #Faz a normalização das colunas selecionadas e já coloca no dataframe\n",
        "\n",
        "  return dataframe #retorna o dataframe após as modificaçoes do pre-processamento"
      ],
      "metadata": {
        "id": "8-W0mYbAl5zq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = carregaBaseDados(\"data.csv\")\n"
      ],
      "metadata": {
        "id": "8aV-FUWevKmc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #verificar a nossa base de dados para o pre-processamento, percebe-se que todas colunas estao com 569 amostras com exceção da coluna 32 que nao possui nada(gerado por ruído/lixo), ou seja precisará ser removida. Outra coluna que pode ser removida é o id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lymxX8Hkv1Sw",
        "outputId": "10eeb289-cfcb-41fc-ecb0-fb9c6bbc3924"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7bqz9dHzII1",
        "outputId": "1359023e-946c-4cb5-bbd9-7f4172c64ea1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
              "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
              "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
              "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
              "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = preProcessamento(df, ['id','Unnamed: 32'], 'diagnosis', ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
        "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
        "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
        "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
        "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
        "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
        "       'symmetry_worst', 'fractal_dimension_worst'])"
      ],
      "metadata": {
        "id": "m0LL_lH9xras"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #verificar como ficou após o pre-processamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDRDwF0-0IPz",
        "outputId": "8eb22eac-8f0a-4b84-c493-b749cc7f58bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    int64  \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar os atributos (previsores) da classe (diagnosis) (X -> previsores, y -> classe)\n",
        "def separaClasse(dataframe, classe):\n",
        "  X = dataframe.drop(classe, axis = 1)\n",
        "  y = dataframe[classe]\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "khwv8qnHdEbH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amostragem Holdout"
      ],
      "metadata": {
        "id": "-MfbWtesfxuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separa os conjuntos em treino e teste (70%/30%)\n",
        "def separaTreinoTeste(X, y):\n",
        "  return train_test_split(X,y,test_size=0.3)"
      ],
      "metadata": {
        "id": "ceAUfsujf1Ug"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Amostragem por validação cruzada, no caso 'K-fold Cross-validation'\n",
        "\n",
        "Parametros do cross_validate():\n",
        "* O model a ser passado é uma string, porem para ele interpretar como uma função de modelo de algoritmo que será executado precisamos usar o 'eval', que quebra essa string e a transforma em uma função a ser\n",
        "* X,y sao os previsores e a classe respectivamente\n",
        "* Scoring é a métrica que será utilizada para verificar o desempenho do classificador\n",
        "* cv é o tipo de validação cruzada que estamos usando"
      ],
      "metadata": {
        "id": "YXfPWzV7j1Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KFCross(model, X, y):\n",
        "  kf = KFold(n_splits = 10, shuffle = True) #n_splits -> numeros de partições (folds). shuffle -> para cada partição faz um novo embaralhamento para garantir que os dados estejam independentes entre si\n",
        "  #objeto que fará a validação cruzada\n",
        "  clf = cross_validate(\n",
        "      eval(model),\n",
        "      X,y,\n",
        "      scoring = 'accuracy',\n",
        "      cv = kf\n",
        "  )\n",
        "  return clf\n"
      ],
      "metadata": {
        "id": "gwJhkriUkCL2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Amostragem por validação cruzada, no caso 'Stratified K-fold Cross-validation'"
      ],
      "metadata": {
        "id": "cxn0gnCorlbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Skf(model, X, y):\n",
        "  skf = StratifiedKFold(n_splits = 10, shuffle = True)\n",
        "  #objeto que fará a validação cruzada\n",
        "  clf = cross_validate(\n",
        "      eval(model),\n",
        "      X,y,\n",
        "      scoring = 'accuracy',\n",
        "      cv = skf\n",
        "  )\n",
        "  return clf"
      ],
      "metadata": {
        "id": "rNtFeanmryvt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo preditivo"
      ],
      "metadata": {
        "id": "n4YMhErV-nVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gera o modelo preditivo (será usado no metodo holdout)\n",
        "def geraModelo(modelo, X_train, y_train):\n",
        "  modelo = eval(modelo) #modelo do parametro será passado por uma string, entao precisamos fazer seu eval para ter efeito no codigo\n",
        "  modelo.fit(X_train, y_train) #treina o modelo\n",
        "  return modelo\n"
      ],
      "metadata": {
        "id": "sr90mjv--rBf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Métricas"
      ],
      "metadata": {
        "id": "TyAxsccIAKfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metricaReport(y_test, y_pred): #y_test ->gabarito do conjunto teste, y_pred -> o que foi predito pelo classificador(algoritmo)\n",
        "  print(classification_report(y_test, y_pred))#imprimir no formato da função classification report"
      ],
      "metadata": {
        "id": "8r7GNrVQAMXN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando com método Holdout"
      ],
      "metadata": {
        "id": "923sxvGnTw3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar atributos previsores e classe\n",
        "X, y = separaClasse(df, 'diagnosis')\n",
        "\n",
        "#Gerar conjunto treino e teste\n",
        "X_train, X_test, y_train, y_test = separaTreinoTeste(X, y) #método Holdout"
      ],
      "metadata": {
        "id": "9OR7w-MCEF9W"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Avalia os dados (nesse caso o modelo é de arvore de decisão)\n",
        "#Aqui estamos utilizando o método de amostragem Holdout\n",
        "modelo = geraModelo('DecisionTreeClassifier()', X_train, y_train)\n",
        "score = modelo.score(X_test, y_test)#retorna automaticamente a acurácia do modelo (ja faz o predict internamente)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "p01q4ow8FfXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fce9e3-fb1a-4b8d-8983-fce66d170251"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Avalia o modelo com mais métricas e detalhes\n",
        "y_pred = modelo.predict(X_test) #retorna as saídas preditas pelo classificador\n",
        "metricaReport(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XeEZPvLFEQ",
        "outputId": "888b7002-0540-4d2b-9195-4d0ff3872b9d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.93      0.96       111\n",
            "           1       0.88      0.98      0.93        60\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.94      0.96      0.94       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testando com métodos de validação cruzada\n",
        "* A função 'cross_validate', dentro das funções criadas 'KFCross' e 'Skf', retorna um dicionário, e dentro desse dicionário estamos mostrando somente os scores do conjunto teste(chave 'test_score') e mostra também a média dos scores dos testes, pois são 10 testes nesse caso.\n",
        "* De forma geral, é mais comum se apoiar por abordagens de validação cruzada do que pelo método Holdout para se fazer as análises"
      ],
      "metadata": {
        "id": "TGFeSwJSM_Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KF\n",
        "cv = KFCross('DecisionTreeClassifier()', X,y)\n",
        "print(f\"{cv['test_score']}\\nMedia: {np.mean(cv['test_score'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKE-KhuSNDm9",
        "outputId": "33a67fec-98c0-4fc9-cfca-47444918b6ac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9122807  0.96491228 0.9122807  0.94736842 0.92982456 0.89473684\n",
            " 0.98245614 0.87719298 0.98245614 0.91071429]\n",
            "Media: 0.931422305764411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KF estratificado\n",
        "cv = Skf('DecisionTreeClassifier()', X,y)\n",
        "print(f\"{cv['test_score']}\\nMedia: {np.mean(cv['test_score'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV9axGJVSLPC",
        "outputId": "4ed46723-f3a0-42c3-d6f2-a8d67da29a08"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.94736842 0.92982456 0.94736842 0.96491228 0.92982456 0.94736842\n",
            " 0.85964912 0.92982456 0.96491228 0.92857143]\n",
            "Media: 0.9349624060150378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando com técnicas de ajustes de hiperparâmetros -> Podem promover um ganho significativo no score (acuracidade) do modelo quando comparado ao classificador sendo utilizado de maneira padrão/\"default\"\n",
        "- Abordagens disponíveis no scikit-learn:\n",
        "    - GridSearchCV: considera exaustivamente todas as combinações de parâmetros (CV - faz aplicação do método de validação cruzada), pode ter resultados melhores do que o randomizedSearch, pois considera todas combinações possíveis. Demora mais tambem;\n",
        "    - RandomizedSearchCV: pesquisa aleatória de parâmetros, em que cada configuração é amostrada a partir de uma distribuição de possíveis valores de parâmetro. (CV - faz aplicação do método de validação cruzada)"
      ],
      "metadata": {
        "id": "m2JX48dt9qUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import sys"
      ],
      "metadata": {
        "id": "c8RdsgXs9slz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GridSearchCV\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "- https://vitalflux.com/grid-search-explained-python-sklearn-examples/\n",
        "\n",
        "Utilizaremos o classificador Arvore de decisão, para o GridSearchCV é necessário especificar qual é o classificador usado (parametro estimator) e tambem o parametro param_grid que é um dicionário com os nomes dos parametros e de seus possiveis valores a serem utilizados que o classificador em questão possui.\n",
        "\n",
        "Obs.: Escolhemos alguns parametros do DecisionTreeClassifier\n",
        "\n",
        "Decision Tree: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ],
      "metadata": {
        "id": "zIkUSSAPAi9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DT = DecisionTreeClassifier() #Especificar qual classificador estamos usando\n",
        "param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "              'splitter': ['best', 'random'],\n",
        "              'max_features': [sys.maxsize, 1.0, 'sqrt', 'log2', None]\n",
        "              } #especificar um dicionário com os nomes dos parametros que utilizaremos do DecisionTreeClassifier bem como seus possiveis valores em formato de lista (esturutra do dicionario-> {chave: valor})"
      ],
      "metadata": {
        "id": "Oe27ALrPAoTu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* max_features -> O número maximo de features (características) a serem consideradas ao procurar a melhor divisão.\n",
        "se for inteiro, obtemos o maior inteiro pela classe sys usando 'sys.maxsize', se for float o maximo de um float é '1.0', tambem pode ser usado raiz quadrada 'sqrt' e 'log2' ou entao 'None' (não é passado nenhum valor para esse parametro) o qual considera que o numero maximo de features é igual a quantidade total de características."
      ],
      "metadata": {
        "id": "UeLKXpTbaKgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instanciar objeto do GridSearchCV\n",
        "g_search = GridSearchCV(estimator = DT, param_grid = param_grid,\n",
        "                        cv = 10, refit = True) #cv = 10 -> quantidade de folds (partições) da validação cruzada, Refit = True -> Ao término da busca do GridSearchCV, que usa o método de validação cruzada, ele pega o melhor resultado (melhor combinação possível) e retreina todo o modelo para a base inteira, aplicando o metodo holdout nesse caso\n",
        "\n"
      ],
      "metadata": {
        "id": "i-Mji5ZXXpbn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinar o GridSearchCV com X_train e y_train feito pelo train_test_split inicalmente no código (abordagem Holdout)"
      ],
      "metadata": {
        "id": "ip3mddjBSN_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.fit(X_train, y_train) #treino holdout\n",
        "print(g_search.best_params_) #melhor combinção"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0nI_XpqhA1w",
        "outputId": "a9331f61-3d32-45f1-d69a-6d700077a4d5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'log_loss', 'max_features': 'sqrt', 'splitter': 'best'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mostrar os atributos que o g_search gera, ele retorna um dicionário\n",
        "g_search.cv_results_.keys()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsY4Cgcxi1to",
        "outputId": "df5ffd96-d083-409c-f898-63e0ffaf3241"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_criterion', 'param_max_features', 'param_splitter', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.cv_results_['mean_test_score'] #média dos testes das partições (splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7or585qCjvp2",
        "outputId": "223e8b35-6627-4f4a-99b5-f94ddc0db31f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92724359, 0.93730769, 0.93230769, 0.93737179, 0.95      ,\n",
              "       0.93237179, 0.9224359 , 0.90967949, 0.93717949, 0.9499359 ,\n",
              "       0.93974359, 0.94974359, 0.93974359, 0.92737179, 0.94224359,\n",
              "       0.91467949, 0.93724359, 0.91480769, 0.94224359, 0.93724359,\n",
              "       0.93974359, 0.94230769, 0.94224359, 0.94230769, 0.96487179,\n",
              "       0.91961538, 0.92987179, 0.92705128, 0.93724359, 0.91224359])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "são 30 valores, pois faz todas combinações possíveis usando os valores  dos parametros que foram passado em 'param_grid', entao em 'criterion' temos 3 possiveis valores, em 'splitter temos 2 possiveis valores e em 'max_features' temos 5 possíveis valores, logo todas combinações possíveis será = 3x2x5 = 30\n",
        "\n",
        "Para cada combinação rodará a validação cruzada com 10 partições, entao cada resultado apresentado é a média de cada 10 partições para cada combinação\n"
      ],
      "metadata": {
        "id": "Ui9GfE7BkPB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#melhor média de score para o conjunto treino (melhor acuracidade)\n",
        "print(g_search.best_score_)\n",
        "#índice onde se encontra essa melhor média de score do conjunto treino\n",
        "print(g_search.best_index_)\n",
        "#melhor combinção usada\n",
        "print(g_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH96HUDmp3-g",
        "outputId": "29f176f0-dd6d-4c87-da88-3151185e110b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9648717948717949\n",
            "24\n",
            "{'criterion': 'log_loss', 'max_features': 'sqrt', 'splitter': 'best'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar a acuracidade (score) do algoritmo para o conjunto teste, o qual o alg. ainda não conhece\n",
        "model = g_search.best_estimator_ #pega o melhor modelo dentre as combinações feitas (Arvore de decisão treinada com os melhores parametros encontrados)\n",
        "model.score(X_test, y_test) #aplicar o modelo no conjunto teste (X_test e y_test), devolve a acuracidade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnPa1SI2vR1y",
        "outputId": "87c02850-8a3a-4509-b315-f16f2bed5957"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinar o GridSearchCV com validação cruzada, que já faz as divisões de conjunto treino e teste automaticamente. Usa-se a base inteira (X, y)"
      ],
      "metadata": {
        "id": "H2CDJ9mnSs2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_search.fit(X, y) #treinar para a base inteira\n",
        "print(g_search.best_params_) #melhor combinção"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi8NwwLWS30H",
        "outputId": "c98cd72f-740f-44ef-a364-043b16dfcca5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'log_loss', 'max_features': 9223372036854775807, 'splitter': 'random'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# melhor media de score com validação cruzada\n",
        "print(g_search.best_score_)\n",
        "# indice onde se encontra essa melhor media de score\n",
        "print(g_search.best_index_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNvn5lzZWX8D",
        "outputId": "210a7f77-e683-4361-a666-765aa7c58224"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.950814536340852\n",
            "21\n"
          ]
        }
      ]
    }
  ]
}