{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/EURvdUl6NE6+wSmmyoJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romulo-souza/IA/blob/main/Aprendizado_De_Maquina_Supervisionado/DecisionTree_Modularizado_BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base de Dados: Breast Cancer\n",
        "* Base de dados: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data (baixar e colocar em arquivos no Colab)\n",
        "* Classe: Diagnosis (M = malignant, B = benign)\n",
        "* Usaremos o algoritmo de arvore de decisão (decision tree) do scikitlearn. LINK: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
      ],
      "metadata": {
        "id": "TBmmdxE2_uRu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgrNjFnL_dV6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Modelo machine learning\n",
        "from sklearn.model_selection import train_test_split #amostragem por holdout\n",
        "from sklearn.preprocessing import StandardScaler #normalização, nesse caso será z score\n",
        "from sklearn.tree import DecisionTreeClassifier #Algortimo de classificação é a arvore de decisão\n",
        "from sklearn.preprocessing import LabelEncoder #transformar dados categoricos (classe diagnosis) em numéricos\n",
        "\n",
        "# Amostragem por Validação Cruzada\n",
        "from sklearn.model_selection import (\n",
        "    KFold, #modelo de validação cruzada\n",
        "    LeaveOneOut, #modelo de validação cruzada\n",
        "    StratifiedKFold, #modelo de validação cruzada\n",
        "    cross_validate #classe, função que realiza a validação cruzada\n",
        ")\n",
        "\n",
        "# Métricas\n",
        "from sklearn.metrics import (recall_score,\n",
        "                             accuracy_score,\n",
        "                             precision_score,\n",
        "                             f1_score)\n",
        "from sklearn.metrics import classification_report # Extrato geral das matricas de classificação"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para carregar/gerar Base de Dados (Dataframe)\n",
        "def carregaBaseDados(nome):\n",
        "  return pd.read_csv(nome)#retorna um dataframe\n"
      ],
      "metadata": {
        "id": "1xUNnOadk2eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento\n",
        "* Parametros da função\n",
        "* dataframe - > dataframe que foi retornado na função carregaBaseDados\n",
        "* rem_cols - > Colunas a serem removidas, serão passadas em forma de uma lista\n",
        "* class_column -> Nome da coluna que é a classe alvo, nesse caso é a coluna diagnosis\n",
        "* normalization_cols -> Especificar quais colunas serão normalizadas,  serão passadas em forma de uma lista\n",
        "\n",
        "obs.: A normalização deve ser aplicada apenas às colunas que são originalmente numéricas na base de dados. As colunas categóricas, mesmo após serem transformadas em números inteiros pelo LabelEncoder, não devem ser normalizadas. Isso ocorre porque o LabelEncoder atribui números inteiros arbitrários às categorias, mas esses números não têm uma ordem ou escala significativa. Normalizar esses dados pode introduzir distorções que não fazem sentido para o modelo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UKky_mYpl0nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preProcessamento(dataframe, rem_cols, class_column, normalization_cols):\n",
        "\n",
        "  #Remoção das colunas irrelevantes\n",
        "  dataframe.drop(rem_cols, axis = 1, inplace = True) #axis = 1 pois é uma coluna, inplace = True para substituir o dataframe original por esse\n",
        "\n",
        "  #Transformar dados categóricos da classe 'diagnosis' em dados numéricos\n",
        "  le = LabelEncoder()\n",
        "  dataframe[class_column] = le.fit_transform(dataframe[class_column]) #os valores categoricos da coluna que tem a classe 'diagnosis' serão substiuídos por uma coluna com codificação de rótulos categóricos\n",
        "  #Normalização dos dados\n",
        "  scaler = StandardScaler()\n",
        "  dataframe[normalization_cols] = scaler.fit_transform(dataframe[normalization_cols]) #Faz a normalização das colunas selecionadas e já coloca no dataframe\n",
        "\n",
        "  return dataframe #retorna o dataframe após as modificaçoes do pre-processamento"
      ],
      "metadata": {
        "id": "8-W0mYbAl5zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = carregaBaseDados(\"data.csv\")\n"
      ],
      "metadata": {
        "id": "8aV-FUWevKmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()# verificar a nossa base de dados para o pre-processamento, percebe-se que todas colunas estao com 569 amostras com exceção da coluna 32 que nao possui nada(gerado por ruído/lixo), ou seja precisará ser removida. Outra coluna que pode ser removida é o id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lymxX8Hkv1Sw",
        "outputId": "07b8a629-b80c-4ed0-b46b-07e745e02e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7bqz9dHzII1",
        "outputId": "f1f73ae4-9b87-48be-dd69-28341f3bc715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
              "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
              "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
              "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
              "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = preProcessamento(df, ['id','Unnamed: 32'], 'diagnosis', ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
        "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
        "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
        "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
        "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
        "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
        "       'symmetry_worst', 'fractal_dimension_worst'])"
      ],
      "metadata": {
        "id": "m0LL_lH9xras"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #verificar como ficou após o pre-processamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDRDwF0-0IPz",
        "outputId": "4112da07-f6e4-4087-dc99-f1b05b210108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    int64  \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar os atributos (previsores) da classe (diagnosis) (X -> previsores, y -> classe)\n",
        "def separaClasse(dataframe, classe):\n",
        "  X = dataframe.drop(classe, axis = 1)\n",
        "  y = dataframe[classe]\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "khwv8qnHdEbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amostragem Holdout"
      ],
      "metadata": {
        "id": "-MfbWtesfxuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separa os conjuntos em treino e teste (70%/30%)\n",
        "def separaTreinoTeste(X, y):\n",
        "  return train_test_split(X,y,test_size=0.3)"
      ],
      "metadata": {
        "id": "ceAUfsujf1Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Amostragem por validação cruzada, no caso 'K-fold Cross-validation' para testar\n",
        "\n",
        "Parametros do cross_validate():\n",
        "* O model a ser passado é uma string, porém, para ele interpretar como uma função de modelo de algoritmo que será executado, precisamos usar o eval(), que converte essa string em um objeto da classe correspondente e permite que o modelo seja instanciado;\n",
        "* X,y sao os previsores e a classe respectivamente;\n",
        "* Scoring é a métrica que será utilizada para verificar o desempenho do classificador;\n",
        "* cv é o tipo de validação cruzada que estamos usando."
      ],
      "metadata": {
        "id": "YXfPWzV7j1Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KFCross(model, X, y):\n",
        "  kf = KFold(n_splits = 10, shuffle = True) #n_splits -> numeros de partições (folds). shuffle -> para cada partição faz um novo embaralhamento para garantir que os dados estejam independentes entre si\n",
        "  #objeto que fará a validação cruzada\n",
        "  clf = cross_validate(\n",
        "      eval(model),\n",
        "      X,y,\n",
        "      scoring = 'accuracy',\n",
        "      cv = kf\n",
        "  )\n",
        "  return clf\n"
      ],
      "metadata": {
        "id": "gwJhkriUkCL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Amostragem por validação cruzada, no caso 'Stratified K-fold Cross-validation' para testar"
      ],
      "metadata": {
        "id": "cxn0gnCorlbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Skf(model, X, y):\n",
        "  skf = StratifiedKFold(n_splits = 10, shuffle = True)\n",
        "  #objeto que fará a validação cruzada\n",
        "  clf = cross_validate(\n",
        "      eval(model),\n",
        "      X,y,\n",
        "      scoring = 'accuracy',\n",
        "      cv = skf\n",
        "  )\n",
        "  return clf"
      ],
      "metadata": {
        "id": "rNtFeanmryvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo preditivo"
      ],
      "metadata": {
        "id": "n4YMhErV-nVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gera o modelo preditivo\n",
        "def geraModelo(modelo, X_train, y_train):\n",
        "  modelo = eval(modelo) #modelo do parametro será passado por uma string, entao precisamos fazer seu eval para ter efeito no codigo\n",
        "  modelo.fit(X_train, y_train) #treina o modelo\n",
        "  return modelo\n"
      ],
      "metadata": {
        "id": "sr90mjv--rBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Métricas"
      ],
      "metadata": {
        "id": "TyAxsccIAKfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metricaReport(y_test, y_pred): #y_test ->gabarito do conjunto teste, y_pred -> o que foi predito pelo classificador(algoritmo)\n",
        "  print(classification_report(y_test, y_pred))#imprimir no formato da função classification report"
      ],
      "metadata": {
        "id": "8r7GNrVQAMXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Teste com os dados"
      ],
      "metadata": {
        "id": "dabX35_CCiJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar atributos previsores e classe\n",
        "X, y = separaClasse(df, 'diagnosis')\n"
      ],
      "metadata": {
        "id": "sEBj_TgtCmbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando com método Holdout"
      ],
      "metadata": {
        "id": "923sxvGnTw3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gerar conjunto treino e teste\n",
        "X_train, X_test, y_train, y_test = separaTreinoTeste(X, y) #método Holdout"
      ],
      "metadata": {
        "id": "9OR7w-MCEF9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Avalia os dados (nesse caso o modelo é de arvore de decisão)\n",
        "#Aqui estamos utilizando o método de amostragem Holdout\n",
        "modelo = geraModelo('DecisionTreeClassifier()', X_train, y_train)\n",
        "score = modelo.score(X_test, y_test)#retorna automaticamente a acurácia do modelo\n",
        "y_pred = modelo.predict(X_test) #retorna as saídas preditas pelo classificador\n",
        "print(score)"
      ],
      "metadata": {
        "id": "p01q4ow8FfXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7549f76-2e07-4ab7-e301-d5ddf1e79259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9005847953216374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Avalia o modelo com mais métricas e detalhes\n",
        "metricaReport(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XeEZPvLFEQ",
        "outputId": "a1ddf093-1539-46e7-89b8-1a761b90ba8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.86      0.92       109\n",
            "           1       0.80      0.97      0.88        62\n",
            "\n",
            "    accuracy                           0.90       171\n",
            "   macro avg       0.89      0.92      0.90       171\n",
            "weighted avg       0.91      0.90      0.90       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testando com métodos de validação cruzada\n",
        "* A função 'cross_validate', dentro das funções criadas 'KFCross' e 'Skf', retorna um dicionário, e dentro desse dicionário estamos mostrando somente os scores do conjunto teste(chave 'test_score') e mostra também a média dos scores dos testes, pois são 10 testes nesse caso.\n",
        "* De forma geral, é mais comum se apoiar por abordagens de validação cruzada do que pelo método Holdout para se fazer as análises"
      ],
      "metadata": {
        "id": "TGFeSwJSM_Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KF\n",
        "cv = KFCross('DecisionTreeClassifier()', X,y)\n",
        "print(f\"{cv['test_score']}\\nMedia: {np.mean(cv['test_score'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKE-KhuSNDm9",
        "outputId": "a079edf2-42bc-4bc0-a2ef-4f829349ded9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96491228 0.85964912 0.89473684 0.96491228 0.94736842 0.94736842\n",
            " 0.89473684 0.87719298 0.89473684 0.92857143]\n",
            "Media: 0.9174185463659148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KF estratificado\n",
        "cv = Skf('DecisionTreeClassifier()', X,y)\n",
        "print(f\"{cv['test_score']}\\nMedia: {np.mean(cv['test_score'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV9axGJVSLPC",
        "outputId": "fe4a0590-65d5-4ef3-8d0b-7c018e7cd3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.89473684 0.84210526 0.96491228 0.96491228 0.96491228 0.92982456\n",
            " 0.94736842 0.9122807  0.94736842 0.92857143]\n",
            "Media: 0.9296992481203008\n"
          ]
        }
      ]
    }
  ]
}